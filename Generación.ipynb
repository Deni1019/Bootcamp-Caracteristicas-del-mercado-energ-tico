{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deni1019/Bootcamp-Caracteristicas-del-mercado-energ-tico/blob/main/Generaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bnJWoG9ODan3"
      },
      "outputs": [],
      "source": [
        "!pip -q install prophet || pip -q install fbprophet\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "except Exception:\n",
        "    from fbprophet import Prophet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import t as student_t\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ruta del archivo en el entorno actual\n",
        "ruta = \"/content/drive/MyDrive/Colab Notebooks/BootCamp TT2/Proyecto/Copia de Variables Bootmcap.xlsx\"\n",
        "\n",
        "# Cargar el Excel\n",
        "df = pd.read_excel(ruta)\n",
        "\n",
        "# Mostrar información general\n",
        "print(\"Dimensiones:\", df.shape)\n",
        "print(\"\\nColumnas:\", df.columns.tolist())\n",
        "\n",
        "df_seleccion = df.iloc[:, [0, 6]]\n",
        "df_seleccion.columns = ['Fecha', 'Generación']\n",
        "\n",
        "print(\"Vista rápida de df_seleccion:\")\n",
        "display(df_seleccion.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zczinsAPD07p",
        "outputId": "43867d6e-3060-4d7b-dc85-634509f071c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/BootCamp TT2/Proyecto/Copia de Variables Bootmcap.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-86851450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Cargar el Excel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Mostrar información general\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/BootCamp TT2/Proyecto/Copia de Variables Bootmcap.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2) Adaptar al formato Prophet (ds, y) ---\n",
        "dfp = df_seleccion.rename(columns={'Fecha':'ds','Demanda':'y'}).copy()\n",
        "# Parseo robusto de fechas y numéricos\n",
        "dfp['ds'] = pd.to_datetime(dfp['ds'], errors='coerce', dayfirst=True)\n",
        "dfp['y']  = pd.to_numeric(dfp['y'], errors='coerce')"
      ],
      "metadata": {
        "id": "PMfpxLV3EGTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza: quitar nulos, ordenar, resolver duplicados por fecha (sum o mean según tu caso)\n",
        "dfp = dfp.dropna(subset=['ds','y']).sort_values('ds')\n",
        "dfp = dfp.groupby('ds', as_index=False)['y'].sum()\n",
        "\n",
        "print(\"Frecuencia inferida:\", pd.infer_freq(dfp['ds']) )\n",
        "display(dfp.head())\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "dfp.to_csv(\"dfp.csv\", index=False)\n",
        "files.download(\"dfp.csv\")"
      ],
      "metadata": {
        "id": "saOZRgz_EIZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(dfp[\"ds\"], dfp[\"y\"], color='blue')\n",
        "plt.title(\"Serie de tiempo de dfp (y vs ds)\")\n",
        "plt.xlabel(\"Fecha\")\n",
        "plt.ylabel(\"Generación [GWh]\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "48410lt3EMMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Modelo base Prophet (sin MCMC) + gráfico completo estilo base ===\n",
        "# Si es la primera vez en Colab:\n",
        "# !pip install -q prophet\n",
        "\n",
        "\n",
        "# 0) Limpieza y preparación (ds: fecha, y: serie)\n",
        "dfp = dfp.dropna(subset=['ds','y']).sort_values('ds')\n",
        "dfp = dfp.groupby('ds', as_index=False)['y'].sum()\n",
        "dfp['ds'] = pd.to_datetime(dfp['ds'])\n",
        "dfp['y']  = pd.to_numeric(dfp['y'], errors='coerce')\n",
        "dfp = dfp.dropna(subset=['y']).reset_index(drop=True)\n",
        "\n",
        "# Si no detecta frecuencia, forzamos mensual al inicio de mes\n",
        "if pd.infer_freq(dfp['ds']) is None:\n",
        "    dfp = (dfp\n",
        "           .assign(ds=lambda d: d['ds'].dt.to_period('M').dt.to_timestamp(how='start'))\n",
        "           .groupby('ds', as_index=False)['y'].sum()\n",
        "           .sort_values('ds')\n",
        "          )\n",
        "\n",
        "# 1) Split: últimos 24 meses como test\n",
        "N_TEST = 24\n",
        "df_train = dfp.iloc[:-N_TEST].copy()\n",
        "df_test  = dfp.iloc[-N_TEST:].copy()\n",
        "\n",
        "# 2) Modelo Prophet (MAP por defecto, sin MCMC)\n",
        "m = Prophet(\n",
        "    yearly_seasonality=True,     # mensual con estacionalidad anual\n",
        "    weekly_seasonality=False,\n",
        "    daily_seasonality=False,\n",
        "    seasonality_mode=\"multiplicative\",\n",
        "    changepoint_range=0.95,\n",
        "    changepoint_prior_scale=0.2,\n",
        "    interval_width=0.90          # un poco menos conservador que 0.95\n",
        ")\n",
        "m.fit(df_train[['ds','y']])\n",
        "\n",
        "# 3) Pronóstico para toda la serie (train + 24 de test)\n",
        "future = m.make_future_dataframe(periods=N_TEST, freq='M')\n",
        "forecast = m.predict(future)\n",
        "\n",
        "# 4) Gráfico estilo base\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "# Observados (train)\n",
        "plt.plot(df_train['ds'], df_train['y'], 'k.', label='Datos observados')\n",
        "\n",
        "# Pronóstico central\n",
        "plt.plot(forecast['ds'], forecast['yhat'], 'b-', label='Predicción', linewidth=2)\n",
        "\n",
        "# Intervalo de incertidumbre\n",
        "plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'],\n",
        "                 color='skyblue', alpha=0.4, label='intervalo de confianza')\n",
        "\n",
        "# Reales (hold-out)\n",
        "plt.plot(df_test['ds'], df_test['y'],'o', mfc='orange', mec='none', mew=1, ms=5, label='Reales (hold-out)')\n",
        "\n",
        "plt.title(\"Prophet – Evaluación en datos existentes\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"Generación [GWh]\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h7SvxenWETGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEa5n_UqUr57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RqQzkhVZjrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predicciones e intervalos en el set de test\n",
        "fcst_test = m.predict(df_test[['ds']])\n",
        "ev_test_plot = df_test[['ds','y']].merge(\n",
        "    fcst_test[['ds','yhat','yhat_lower','yhat_upper']], on='ds', how='left'\n",
        ")\n",
        "\n",
        "# Naive: constante = último valor del train\n",
        "last_train_val = df_train['y'].iloc[-1]\n",
        "naive_test_pred = np.full(len(df_test), last_train_val)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(ev_test_plot['ds'], ev_test_plot['y'], 'k-', label='Real')\n",
        "plt.plot(ev_test_plot['ds'], ev_test_plot['yhat'], 'b-', label='Prophet Predicción')\n",
        "plt.fill_between(ev_test_plot['ds'], ev_test_plot['yhat_lower'], ev_test_plot['yhat_upper'],\n",
        "                 color='skyblue', alpha=0.4, label='Prophet intervalo de confianza 90%')\n",
        "plt.plot(ev_test_plot['ds'], naive_test_pred, 'r--', label='Naive Predicción')\n",
        "plt.title(\"Comparación Prophet vs Naive – Conjunto de Test\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"Generación [GWh]\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "vJAnwelGGYzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Funciones\n",
        "def rmse(y, yhat):  return float(np.sqrt(np.mean((y - yhat)**2)))\n",
        "def mape(y, yhat):  return float(np.mean(np.abs((y - yhat) / y)) * 100)\n",
        "\n",
        "# --- Predicciones Prophet en train y test ---\n",
        "fcst_train = m.predict(df_train[['ds']])\n",
        "fcst_test  = m.predict(df_test[['ds']])\n",
        "\n",
        "ev_train = df_train[['ds','y']].merge(fcst_train[['ds','yhat']], on='ds', how='left')\n",
        "ev_test  = df_test[['ds','y']].merge(fcst_test[['ds','yhat']],   on='ds', how='left')\n",
        "\n",
        "rmse_train = rmse(ev_train['y'].values, ev_train['yhat'].values)\n",
        "mape_train = mape(ev_train['y'].values, ev_train['yhat'].values)\n",
        "\n",
        "rmse_test  = rmse(ev_test['y'].values,  ev_test['yhat'].values)\n",
        "mape_test  = mape(ev_test['y'].values,  ev_test['yhat'].values)\n",
        "\n",
        "# --- Modelo Naive ---\n",
        "# Train: predice cada punto como el valor anterior (lag-1)\n",
        "naive_train_pred = ev_train['y'].shift(1)\n",
        "rmse_train_naive = rmse(ev_train['y'].iloc[1:].values, naive_train_pred.iloc[1:].values)\n",
        "mape_train_naive = mape(ev_train['y'].iloc[1:].values, naive_train_pred.iloc[1:].values)\n",
        "\n",
        "# Test: predice todo como el último valor del train\n",
        "last_train_val   = df_train['y'].iloc[-1]\n",
        "naive_test_pred  = np.repeat(last_train_val, len(df_test))\n",
        "rmse_test_naive  = rmse(ev_test['y'].values, naive_test_pred)\n",
        "mape_test_naive  = mape(ev_test['y'].values, naive_test_pred)\n",
        "\n",
        "# --- Comparación ---\n",
        "print(\"=== Prophet REGULARIZADO ===\")\n",
        "print(f\"RMSE Train: {rmse_train:.2f} | MAPE Train: {mape_train:.2f}%\")\n",
        "print(f\"RMSE Test:  {rmse_test:.2f} | MAPE Test:  {mape_test:.2f}%\")\n",
        "\n",
        "print(\"\\n=== Naive ===\")\n",
        "print(f\"RMSE Train: {rmse_train_naive:.2f} | MAPE Train: {mape_train_naive:.2f}%\")\n",
        "print(f\"RMSE Test:  {rmse_test_naive:.2f} | MAPE Test:  {mape_test_naive:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9JHXbdPfEfp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Predicciones del modelo ACTUAL (Prophet base + dummy COVID si existe) y Naive en el mismo hold-out ===\n",
        "# Armar columnas necesarias para predecir con el modelo actual `m`\n",
        "reg_cols = [c for c in ['covid_dummy','postcovid_dummy','ramp_postcovid'] if c in df_test.columns]\n",
        "fcst_test = m.predict(df_test[['ds'] + reg_cols])\n",
        "\n",
        "# Emparejar con observados\n",
        "ev_test_cur = df_test[['ds','y']].merge(fcst_test[['ds','yhat']], on='ds', how='left')\n",
        "y_test = ev_test_cur['y'].to_numpy(dtype=float)\n",
        "yhat_prophet = ev_test_cur['yhat'].to_numpy(dtype=float)\n",
        "\n",
        "# Naive: todos los puntos del test = último valor del train\n",
        "last_train_val = float(df_train['y'].iloc[-1])\n",
        "yhat_naive = np.full_like(y_test, fill_value=last_train_val, dtype=float)\n",
        "\n",
        "# === Diebold–Mariano (con Newey–West y corrección HLN) ===\n",
        "def diebold_mariano(y_true, yhat_1, yhat_2, h=1, loss='MSE'):\n",
        "    \"\"\"\n",
        "    Compara modelo 1 vs modelo 2 en el MISMO hold-out.\n",
        "    loss: 'MSE' (cuadrática) o 'MAE' (absoluta)\n",
        "    h: horizonte de pronóstico; para multi-step overlapped usar h>1 (NW con L=h-1)\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true, float)\n",
        "    yhat_1 = np.asarray(yhat_1, float)\n",
        "    yhat_2 = np.asarray(yhat_2, float)\n",
        "\n",
        "    if loss.upper() == 'MSE':\n",
        "        d = (y_true - yhat_1)**2 - (y_true - yhat_2)**2\n",
        "    elif loss.upper() == 'MAE':\n",
        "        d = np.abs(y_true - yhat_1) - np.abs(y_true - yhat_2)\n",
        "    else:\n",
        "        raise ValueError(\"loss debe ser 'MSE' o 'MAE'\")\n",
        "\n",
        "    T = d.size\n",
        "    d_bar = d.mean()\n",
        "\n",
        "    # Varianza HAC Newey–West (kernel Bartlett)\n",
        "    if h > 1:\n",
        "        L = max(1, h - 1)\n",
        "    else:\n",
        "        L = int(np.floor(T**(1/3)))  # regla simple cuando h=1\n",
        "    d_c = d - d_bar\n",
        "    gamma0 = np.dot(d_c, d_c) / T\n",
        "    s = gamma0\n",
        "    for k in range(1, L + 1):\n",
        "        gamma_k = np.dot(d_c[k:], d_c[:-k]) / T\n",
        "        w = 1.0 - k / (L + 1.0)\n",
        "        s += 2.0 * w * gamma_k\n",
        "    var_dbar = s / T\n",
        "    dm = d_bar / (np.sqrt(var_dbar) + 1e-12)\n",
        "\n",
        "    # Corrección Harvey–Leybourne–Newbold y p-valor\n",
        "    c = np.sqrt((T + 1 - 2*h + (h*(h-1))/T) / T) if h > 1 else 1.0\n",
        "    dm_hln = dm * c\n",
        "    pval = 2 * (1 - student_t.cdf(np.abs(dm_hln), df=T - 1))\n",
        "    return dm_hln, pval, d_bar, var_dbar\n",
        "\n",
        "# Ejecutar DM para MSE y MAE\n",
        "dm_mse_stat, dm_mse_p, dbar_mse, _ = diebold_mariano(y_test, yhat_prophet, yhat_naive, h=1, loss='MSE')\n",
        "dm_mae_stat, dm_mae_p, dbar_mae, _ = diebold_mariano(y_test, yhat_prophet, yhat_naive, h=1, loss='MAE')\n",
        "\n",
        "print(\"=== Diebold–Mariano: Prophet (modelo 1) vs Naive (modelo 2) ===\")\n",
        "print(f\"MSE:  DM={dm_mse_stat:.3f}  p-value={dm_mse_p:.4f}  d_bar={dbar_mse:.3f}  \"\n",
        "      f\"({'Prophet mejor' if dbar_mse<0 else 'Naive mejor' if dbar_mse>0 else 'Empate'})\")\n",
        "print(f\"MAE:  DM={dm_mae_stat:.3f}  p-value={dm_mae_p:.4f}  d_bar={dbar_mae:.3f}  \"\n",
        "      f\"({'Prophet mejor' if dbar_mae<0 else 'Naive mejor' if dbar_mae>0 else 'Empate'})\")\n"
      ],
      "metadata": {
        "id": "SsHJfrCCHOLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 0) Preparación de datos --------\n",
        "dfp = dfp.dropna(subset=['ds','y']).sort_values('ds')\n",
        "dfp = dfp.groupby('ds', as_index=False)['y'].sum()\n",
        "dfp['ds'] = pd.to_datetime(dfp['ds'])\n",
        "dfp['y']  = pd.to_numeric(dfp['y'], errors='coerce')\n",
        "dfp = dfp.dropna(subset=['y']).reset_index(drop=True)\n",
        "\n",
        "if pd.infer_freq(dfp['ds']) is None:\n",
        "    dfp = (dfp.assign(ds=lambda d: d['ds'].dt.to_period('M').dt.to_timestamp(how='start'))\n",
        "               .groupby('ds', as_index=False)['y'].sum())\n",
        "\n",
        "# -------- 1) Cap/Floor si logistic --------\n",
        "use_logistic = 'cap' in dfp.columns or 'floor' in dfp.columns\n",
        "if use_logistic:\n",
        "    if 'cap' not in dfp.columns:\n",
        "        cap_value = dfp['y'].max() * 1.15\n",
        "        dfp['cap'] = cap_value\n",
        "    if 'floor' not in dfp.columns:\n",
        "        dfp['floor'] = 0.0\n",
        "\n",
        "# -------- 2) Regresores --------\n",
        "candidate_regs = ['covid_dummy', 'postcovid_dummy', 'ramp_postcovid']\n",
        "reg_cols = [c for c in candidate_regs if c in dfp.columns]\n",
        "\n",
        "# -------- 3) Modelo REGULARIZADO --------\n",
        "m_reg = Prophet(\n",
        "    growth=(\"logistic\" if use_logistic else \"linear\"),\n",
        "    yearly_seasonality=False,\n",
        "    weekly_seasonality=False,\n",
        "    daily_seasonality=False,\n",
        "    seasonality_mode=\"multiplicative\",\n",
        "    changepoint_prior_scale=0.10,\n",
        "    changepoint_range=0.90,\n",
        "    n_changepoints=40,\n",
        "    interval_width=0.90\n",
        ")\n",
        "m_reg.add_seasonality(name='yearly', period=365.25, fourier_order=10)\n",
        "\n",
        "for c in reg_cols:\n",
        "    mode = \"additive\" if \"covid\" in c else \"multiplicative\"\n",
        "    m_reg.add_regressor(c, prior_scale=5.0, mode=mode)\n",
        "\n",
        "fit_cols = ['ds','y'] + (['cap','floor'] if use_logistic else []) + reg_cols\n",
        "m_reg.fit(dfp[fit_cols])\n",
        "\n",
        "# -------- 4) Predicción a 3 años --------\n",
        "future = m_reg.make_future_dataframe(periods=36, freq='M')\n",
        "if use_logistic:\n",
        "    future['cap'] = dfp['cap'].iloc[-1]\n",
        "    future['floor'] = dfp['floor'].iloc[-1]\n",
        "\n",
        "for c in reg_cols:\n",
        "    if c in dfp.columns:\n",
        "        if c in ['covid_dummy','postcovid_dummy']:\n",
        "            future[c] = ((future['ds'] >= dfp['ds'].min())).astype(int)\n",
        "        elif c == 'ramp_postcovid':\n",
        "            postcovid_ini = pd.to_datetime(\"2021-04-01\")\n",
        "            span_f = (future['ds'].max() - postcovid_ini).days\n",
        "            future['ramp_postcovid'] = 0.0\n",
        "            mask_f = future['ds'] >= postcovid_ini\n",
        "            future.loc[mask_f, 'ramp_postcovid'] = (future.loc[mask_f, 'ds'] - postcovid_ini).dt.days / max(span_f,1)\n",
        "\n",
        "forecast = m_reg.predict(future)\n",
        "\n",
        "# Definir fecha de inicio para graficar\n",
        "zoom_start = pd.to_datetime(\"2018-01-01\")\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "# Observados desde 2018\n",
        "mask_obs = dfp['ds'] >= zoom_start\n",
        "plt.plot(dfp.loc[mask_obs, 'ds'], dfp.loc[mask_obs, 'y'], 'k.', label='Observado')\n",
        "\n",
        "# Forecast desde 2018\n",
        "mask_fcst = forecast['ds'] >= zoom_start\n",
        "plt.plot(forecast.loc[mask_fcst, 'ds'], forecast.loc[mask_fcst, 'yhat'], 'b-', label='Pronóstico', linewidth=2)\n",
        "\n",
        "# Intervalo de incertidumbre\n",
        "plt.fill_between(forecast.loc[mask_fcst, 'ds'],\n",
        "                 forecast.loc[mask_fcst, 'yhat_lower'],\n",
        "                 forecast.loc[mask_fcst, 'yhat_upper'],\n",
        "                 color='skyblue', alpha=0.4, label='intervalo de confianza')\n",
        "\n",
        "plt.title(\"Prophet – Predicción a 3 años\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"Generación [GWh]\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "9W7cFP8NvaI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}